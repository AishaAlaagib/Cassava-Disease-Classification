{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "train_paths=[]\n",
    "train_labels=[]\n",
    "for root,dir,files in os.walk(\"data/train\"):\n",
    "    for file in files:\n",
    "        train_paths.append(os.path.join(root,file))\n",
    "        train_labels.append(root.split(\"/\")[-1])\n",
    "\n",
    "test_paths=[]\n",
    "for root,dir,files in os.walk(\"data/test\"):\n",
    "    for file in files:\n",
    "        test_paths.append(os.path.join(root,file))\n",
    "        \n",
    "print(train_paths[:5])\n",
    "print(test_paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to preprocess images and labels\n",
    "def preprocess_image(image,image_shape=[192,192]):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_shape)\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(file,image_shape):\n",
    "    image = tf.io.read_file(file)\n",
    "    return preprocess_image(image,image_shape)\n",
    "\n",
    "labs2index={'cbb':0, 'cbsd':1, 'cgm':2, 'cmd':3, 'healthy':4}\n",
    "index2labs={0:'cbb', 1:'cbsd', 2:'cgm', 3:'cmd', 4:'healthy'}\n",
    "\n",
    "\n",
    "def process_labels(lab):\n",
    "    print(lab)\n",
    "    return tf.one_hot(lab,depth=len(labs2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tensorflow data objects\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "test_ds=tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "\n",
    "train_image_ds = train_ds.map(lambda x:load_and_preprocess_image(x,image_shape=[192,192]),num_parallel_calls=AUTOTUNE)\n",
    "test_image_ds=test_ds.map(lambda x:load_and_preprocess_image(x,image_shape=[192,192]),num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "train_label_ds=tf.data.Dataset.from_tensor_slices([labs2index[i] \n",
    "                                                   for i in train_labels]).map(process_labels,num_parallel_calls=AUTOTUNE)\n",
    "image_label_ds=tf.data.Dataset.zip((train_image_ds,train_label_ds))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "# completely shuffled.\n",
    "ds = image_label_ds.shuffle(buffer_size=len(train_paths))\n",
    "ds = ds.repeat()\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "# `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
    "ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "ds_test=test_image_ds.batch(BATCH_SIZE)\n",
    "print(ds)\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pretrained model\n",
    "resnet = tf.keras.applications.VGG19(input_shape=(192, 192, 3), include_top=False)\n",
    "#mobile_net.trainable=False\n",
    "\n",
    "def change_range(image,label):\n",
    "    \n",
    "    return 2*image-1, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_ds = ds.map(change_range)\n",
    "keras_test=ds_test.map(lambda x:2*x-1)\n",
    "\n",
    "\n",
    "#image_batch, label_batch = next(iter(keras_ds))\n",
    "\n",
    "model = tf.keras.Sequential([resnet, tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                             tf.keras.layers.Dense(len(labs2index),activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model for 50 epochs\n",
    "model.fit(keras_ds, epochs=10, steps_per_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "test_predictions=model.predict(keras_test,steps=int(np.ceil(len(test_paths)/BATCH_SIZE)))\n",
    "predictions=np.argmax(test_predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make submission\n",
    "my_submission = pd.DataFrame({'Category':[index2labs[j] for j in predictions],'Id':[i.split(\"/\").pop() for i in test_paths]})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)\n",
    "print(my_submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}